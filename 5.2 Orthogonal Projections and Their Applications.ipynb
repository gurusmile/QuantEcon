{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orthogonal Projections and Their Applications\n",
    "正交投影"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正交投影是向量空间方法的基石,应用于：   \n",
    "- 最小二乘投影（线性回归）\n",
    "- 多元正态（高斯）分布的条件期望\n",
    "- 格兰-施密特正交化       \n",
    "- QR分解\n",
    "- 正交多项式  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Key Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假定$x,z\\in\\mathbb{R}^n$,定义$\\langle x,z\\rangle=\\sum_i x_i z_i$,回顾$\\|x\\|^2=\\langle x,x\\rangle$，由**余弦定理**得到$\\langle x,z\\rangle=\\|x\\|\\ \\|z\\|cos(\\theta)$,其中$\\theta$是夹角。如果$cos(\\theta)=0$，那么就说$x$和$z$是正交的，写为$x\\perp z$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"https://lectures.quantecon.org/_images/orth_proj_def1.png\" width=\"50%\" height=\"50%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果$x\\perp z$,且$z\\in S$,那么$x\\perp S$。\n",
    "<img  src=\"https://lectures.quantecon.org/_images/orth_proj_def2.png\"  width=\"50%\" height=\"50%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**线性子空间$S\\subset RR^n$的正交补集是集合**$S^{\\perp}:=\\{x\\in \\mathbb R^n:x\\perp S\\}$\n",
    "<img src=\"https://lectures.quantecon.org/_images/orth_proj_def3.png\"  width=\"50%\" height=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**正交集** $x_1,...,x_k\\subset\\mathbb R^n$，其中$x_i\\perp x_j,i\\neq j$。\n",
    "由$毕德哥拉斯定理$，有\n",
    "$$\\|x_1+...+x_k\\|^2=\\|x_1\\|^2+...+\\|x_k\\|^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Independence vs Orthogonality\n",
    "如果$X\\subset \\mathbb R^n$是正交集，且$0\\not\\in X$,那么$X$是线性独立的。\n",
    "## 3.The Orthogonal Projection Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定一个向量，我们想在某一线性空间中找到最能近似替代这一给定向量的向量，正交投影解决了这个问题。 \n",
    "**正交投影定理**给定$y\\in\\mathbb R^n$且线性子空间$S\\subset \\mathbb R^n$，那么存在最小化问题：\n",
    "$$\\hat y:=\\arg\\min_{z\\in S}\\|y-z\\|$$\n",
    "唯一的最小化$\\hat y$满足\n",
    "- $\\hat y \\in S$\n",
    "- $y-\\hat y \\perp S$  \n",
    "\n",
    "向量 $\\hat y$ 是向量y在S上的正交投影。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://lectures.quantecon.org/_images/orth_proj_thm1.png\"  width=\"50%\" height=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof of sufficiency\n",
    "$\\hat y$是一个向量，且$\\hat y\\in S$，$y-\\hat y\\perp S$，$z$是$S$中任意的其他向量，可以推导\n",
    "$$\\|y-z\\|^2=\\|(y-\\hat y)+(\\hat y -z)\\|^2=\\|y-\\hat y\\|^2+\\|\\hat y-z\\|^2$$\n",
    "因此$\\|y-z\\| \\geq\\|y-\\hat y\\|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonal Projection as a Mapping\n",
    "给定线性空间$S$，对于另一线性空间$Y$，有\n",
    "$$y\\in Y \\to \\text{它的正交投影}\\hat y\\in S$$\n",
    "有矩阵$P$\n",
    "\n",
    "-  $Py$代表投影$\\hat y$\n",
    "-  $\\hat E_S y=Py$，其中$\\hat E$是广义期望因子\n",
    "\n",
    "$P$是S上的正交投影映射"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://lectures.quantecon.org/_images/orth_proj_thm2.png\"  width=\"50%\" height=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $Py\\in S$\n",
    "2. $y-Py\\perp S$  \n",
    "\n",
    "可以推导出有用的属性：\n",
    "\n",
    "1. $\\|y\\|^2=\\|Py\\|^2+\\|y-Py\\|^2$\n",
    "2. $\\|Py\\| \\leq \\|y\\|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonal Complement\n",
    "**定义** $S$的正交补集是线性子空间$S^\\perp$，满足$x_1\\perp x_2$，对于$x_1\\in S$和$x_2\\in S^\\perp$。  \n",
    "线性空间$Y$包含线性子空间$S$和它的正交补集$S^\\perp$，写为\n",
    "$$Y=S\\oplus S^\\perp$$\n",
    "对于每个$y\\in Y$，有唯一的$x_1\\in S$和唯一的$x_2\\in S^\\perp$，使得$y=x_1+x_2$。也就是$x_1=\\hat E_S y$和$x_2=y-\\hat E_S y$，$x_1$是$y$在$S$上的正交投影。\n",
    "\n",
    "**定理** 如果$S$是$\\mathbb R^n $的线性子空间，$\\hat E_S y=Py$并且$\\hat E_{S^\\perp}y=My$，有\n",
    "$$Py\\perp My \\ \\text{and} \\ y=Py+My \\ \\text{for all} \\ y\\in \\mathbb R^n$$ \n",
    "<img src=\"https://lectures.quantecon.org/_images/orth_proj_thm3.png\"  width=\"50%\" height=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Orthonormal Basis\n",
    "**标准正交集**  \n",
    "如果对于所有$u\\in O\\subset \\mathbb R^n$，有$\\|u\\|=1$，那么正交向量集$O$是标准正交集。  \n",
    "\n",
    "**标准正交基**  \n",
    "如果$S$是$\\mathbb R^n$的线性子空间，$O\\subset S$，$O$是正交的并且$\\text{span}O = S$，那么$O$被称为$S$的标准正交基。  \n",
    "\n",
    "**组合**  \n",
    "如果$\\{u_1,...,u_k\\}$是线性子空间$S$的标准正交基，那么\n",
    "$$x=\\sum_{i=1}^k \\langle x,u_i \\rangle u_i \\ \\text{for all} \\ x\\in S$$\n",
    "\n",
    "如果$x\\in \\text{span}\\{u_1,...,u_k\\}$，可以找到标量$\\alpha_1,...,\\alpha_k$来证实\n",
    "$$x=\\sum_{j=1}^k \\alpha_j u_j$$\n",
    "内积为\n",
    "$$\\langle x,u_i \\rangle=\\sum_{j=1}^k \\alpha_j \\langle u_j, u_i \\rangle = \\alpha_i$$\n",
    "与上式结合起来可以得到前面的结论\n",
    "\n",
    "### Projection onto an Orthonormal Basis\n",
    "**定理** 如果$\\{u_1,...,u_k\\}$是$S$的标准正交基，那么\n",
    "$$Py=\\sum_{i=1}^k \\langle y,u_i \\rangle u_i, \\ \\forall y\\in\\mathbb R^n$$\n",
    "**证明** $y\\in\\mathbb R^n$，$Py$定义为上式，明显的$Py\\in S$，$y-Py \\perp S$也存在，同样的，$y-Py \\perp u_i$，因为\n",
    "$$\\langle y-\\sum_{i=1}^k \\langle y,u_i \\rangle u_i,u_j \\rangle =\\langle y,u_j \\rangle -\\sum_{i=1}^k \\langle y,u_i\\rangle\\langle u_i,u_j\\rangle=0$$\n",
    "\n",
    "## 5. Projection Using Matrix Algebra\n",
    "想要计算矩阵$P$使得\n",
    "$$\\hat E_S y=Py$$\n",
    "明显的$Py$是$y\\in\\mathbb R^n$的线性函数。\n",
    "\n",
    "**定理** $X_{n\\times k}$的列向量是$S$的基，有\n",
    "$$P=X(X'X)^{-1}X'$$\n",
    "\n",
    "**证明** 给定随机数$y\\in\\mathbb R^n$，并且$P=X(X'X)^{-1}X'$，证明\n",
    "1. $Py\\in S$\n",
    "2. $y-Py\\perp S$\n",
    "\n",
    "证明1 \n",
    "$$Py=X(X'X)^{-1}X'y=Xa \\ \\text{when} \\ a:=(X'X)^{-1}X'y$$\n",
    "$Xa$是$X$列向量的线性组合，是$S$的一个元素。  \n",
    "\n",
    "证明2  \n",
    "$$y-X(X'X)^{-1}X'y\\perp Xb \\ \\ \\forall b\\in\\mathbb R^K$$\n",
    "如果$b\\in\\mathbb R^K$,有\n",
    "$$(Xb)'[y-X(X'X)^{-1}X'y]=b'[X'y-X'y]=0$$\n",
    "\n",
    "### Starting with $X$\n",
    "矩阵$X_{n\\times k}$的各列是线性独立的，并且\n",
    "$$S:=\\text{span} X:=\\text{span}\\{\\text{col}_1X,...,\\text{col}_kX\\}$$\n",
    "$X$的各列可以组成$S$的基。$P=X(X'X)^{-1}X'$可以将$y$投射到$S$上，因此也被称作**投射矩阵**。$M=I-P$满足$My=\\hat E_{S^\\perp}y$也被称作**歼灭矩阵**（annihilator matrix）。\n",
    "\n",
    "### The Orthonormal Case\n",
    "假定$U_{n\\times k}$有标准正交列向量，$S:=\\text{span}U$，投射$y$到$S$上：\n",
    "$$Py=U(U'U)^{-1}U'y$$\n",
    "因为$U_{n\\times k}$有标准正交列向量，所以$U'U=I$,因此\n",
    "$$Py=UU'y=\\sum_{i=1}^k\\langle u_i,y\\rangle u_i$$\n",
    "\n",
    "### Application: Overdetermined Systems of Equations\n",
    "$X_{n\\times k}$是由线性无关的列向量组成的，$y\\in\\mathbb R^n$，给定$X$和$y$，我们试图找到$b\\in\\mathbb R^k$满足$Xb=y$。如果$n>k$，$b$是过度决定的，直觉上可能不能找到$b$满足所有$n$个等式。\n",
    "\n",
    "有两个方法\n",
    "- 接受确定解可能不存在\n",
    "- 寻求近似解（$Xb$尽可能的接近$y$）\n",
    "\n",
    "**定理** $\\|y-Xb\\|$最小化得到\n",
    "$$\\hat \\beta:=(X'X)^{-1}X'y=Py$$\n",
    "**证明** 注意\n",
    "$$X\\hat\\beta=X(X'X)^{-1}X'y=Py$$\n",
    "$Py$是在$\\text{span}(X)$上的投影，我们有\n",
    "$$\\|y-Py\\|\\leq\\|y-z\\| \\ \\text{for any} \\ z\\in\\text{span}(X)$$ \n",
    "因为$Xb\\in\\text{span}(X)$\n",
    "$$\\|y-X\\hat\\beta\\|\\leq\\|y-Xb\\| \\ \\text{for any}\\ b\\in\\mathbb R^K $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"\"  width=\"50%\" height=\"50%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Least Squares Regression\n",
    "### Squared risk measures\n",
    "给定pairs$(x,y)\\in\\mathbb{R}^K\\times\\mathbb{R}$，考虑选择$f:\\mathbb{R}^K\\to\\mathbb{R}$来最小化风险\n",
    "$$R(f):=\\mathbb{E}[(y-f(x))^2]$$\n",
    "如果概率，$\\mathbb E$不可知，但是样本可用，我们可以估计**经验风险**：\n",
    "$$\\min_{f\\in\\mathcal F}\\frac{1}{N}\\sum_{n=1}^N(y_n-f(x_n))^2$$\n",
    "最小化上式称为**经验风险最小化**。\n",
    "\n",
    "如果使$\\mathcal F$为线性方程组$1/N$，问题变为**线性最小二乘问题**：\n",
    "$$\\min_{b\\in\\mathbb R^K}\\sum_{n=1}^N(y_n-b'x_n)^2$$\n",
    "\n",
    "### Solution\n",
    "设定矩阵$X_{N\\times K}$，其中$N>K$，且$X$满秩。可以证明$\\|y-Xb\\|^2=\\sum_{n=1}^N(y_n-b'x_n)^2$。单调变化不影响最小化，因此有\n",
    "$$\\arg\\min_{b\\in\\mathbb R^K}\\sum_{n=1}^N(y_n-b'x_n)^2=\\arg\\min_{b\\in\\mathbb R^K}\\|y-Xb\\|$$\n",
    "解为\n",
    "$$\\hat \\beta:=(X'X)^{-1}X'y$$\n",
    "令$P$和$M$为关于$X$的投影和歼灭：\n",
    "$$P:=X(X'X)^{-1}X' \\ \\text{and} \\ M:=I-P$$\n",
    "拟合值向量：\n",
    "$$\\hat y:=X\\hat\\beta=Py$$\n",
    "残差向量：\n",
    "$$\\hat u:=y-\\hat y=y-Py=My$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 7. Orthogonalization and Decomposition\n",
    "下面探讨线性独立与正交化的关系。\n",
    "### Gram-Schmidt Orthogonalization\n",
    "**定理** 对于每个线性独立集$\\{x_1,...,x_k\\}\\subset\\mathbb R^n$，存在标准正交集$\\{u_1,...,u_k\\}$\n",
    "$$\\text{span}\\{x_1,...,x_k\\}=\\text{span}\\{u_1,...,u_k\\}\\ \\text{for} \\ i=1,...,k$$\n",
    "\n",
    "**格兰-施密特正交化**\n",
    "创建正交集的方法\n",
    "- 1. 设$v_1=x_1$\n",
    "- 2. 对于$i\\neq 2$，设$v_i:=\\hat E_{S_{i=1}^\\perp}x_i$，$u_i:=v_i/\\|v_i\\|$\n",
    "\n",
    "### QR Decomposition\n",
    "**定理** 列向量线性不相关的矩阵$X_{n\\times k}$，存在$X=QR$，其中：\n",
    "\n",
    "- $R_{k\\times k}$上三角，非奇异\n",
    "- $Q_{n\\times k}$有标准正交列向量\n",
    "\n",
    "### Linear Regression via QR Decomposition\n",
    "$$y=X\\beta$$\n",
    "$$\\hat\\beta=(X'X)^{-1}X'y$$\n",
    "$$X=QR$$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\hat\\beta & =(R'Q'QR)^{-1}R'Q'y \\\\\n",
    "& = (R'R)^{-1}R'Q'y \\\\\n",
    "& = R^{-1}(R')^{-1}R'Q'y=R^{-1}Q'y\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "## 8.Exercises\n",
    "### Exercise 3\n",
    "使用格兰-施密特正交化方法，投影矩阵$P:=X(X'X)^{-1}X'$，并且使用$QR$分解，解出$y$在$X$列空间上的线性投影。$y:=\\begin{pmatrix}\n",
    "1 \\\\\n",
    "3\\\\\n",
    "-3\n",
    "\\end{pmatrix}$，$X:=\\begin{pmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & -6 \\\\\n",
    "2 & 2\n",
    "\\end{pmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def gram_schmidt(X):\n",
    "    \"\"\"\n",
    "    Implements Gram-Schmidt orthogonalization.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : an n x k array with linearly independent columns\n",
    "    Returns\n",
    "    -------\n",
    "    U : an n x k array with orthonormal columns\n",
    "    \"\"\"\n",
    "    # Set up\n",
    "    n, k = X.shape\n",
    "    U = np.empty((n, k))\n",
    "    I = np.eye(n)\n",
    "    # The first col of U is just the normalized first col of X\n",
    "    v1 = X[:,0]\n",
    "    U[:, 0] = v1 / np.sqrt(np.sum(v1 * v1))\n",
    "    for i in range(1, k):\n",
    "        # Set up\n",
    "        b = X[:,i] # The vector we're going to project\n",
    "        Z = X[:, 0:i] # first i-1 columns of X\n",
    "        # Project onto the orthogonal complement of the col span of Z\n",
    "        M = I - Z @ np.linalg.inv(Z.T @ Z) @ Z.T  # M=I-Z(Z'Z)^{-1}Z'\n",
    "        u = M @ b\n",
    "        # Normalize\n",
    "        U[:,i] = u / np.sqrt(np.sum(u * u))\n",
    "    return U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将向量及矩阵带入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = [1, 3, -3]\n",
    "X = [[1, 0],\n",
    "     [0, -6],\n",
    "     [2, 2]]\n",
    "X, y = [np.asarray(z) for z in (X, y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "普通矩阵表示法下的y在列向量空间X上的投影"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.56521739,  3.26086957, -2.2173913 ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Py1 = X @ np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "Py1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "格兰-施密特正交化方法下的y在列向量空间X上的投影"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4472136 , -0.13187609],\n",
       "       [ 0.        , -0.98907071],\n",
       "       [ 0.89442719,  0.06593805]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = gram_schmidt(X)\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.56521739,  3.26086957, -2.2173913 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Py2 = U @ U.T @ y\n",
    "Py2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果一样！再用QR分解法来验证结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4472136 , -0.13187609],\n",
       "       [-0.        , -0.98907071],\n",
       "       [-0.89442719,  0.06593805]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.linalg import qr\n",
    "Q, R = qr(X, mode='economic')\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.56521739,  3.26086957, -2.2173913 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Py3 = Q @ Q.T @ y\n",
    "Py3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果依旧一样"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
